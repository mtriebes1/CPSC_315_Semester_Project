{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd098b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Weather Classification -- Sydney, Australia\n",
    "## Scott Campbell, Matthew Triebes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Dataset description\n",
    "We sourced our dataset from Kaggle.com: https://www.kaggle.com/jsphyg/weather-dataset-rattle-package\n",
    "\n",
    "When we examined the dataset, we realized that the dataset is a little too large to analyze. Because of this, we've decided to focus our efforts on examining the rain data out of Sydney Australia. That should limit the data to about 3400 instances which will make it a lot easier to analyze. \n",
    "\n",
    "With that taken into account, we’ve made separate files based on the 9am and 3pm data. Comparing those results should be interesting and we’ll see is there is much of a difference.\n",
    "\n",
    "### Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pickle\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MySimpleLinearRegressor, MyNaiveBayesClassifier, MyDecisionTreeClassifier, MyRandomForestClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation"
   ]
  },
  {
   "source": [
    "## Loading the Dataset into Data Science Table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<mysklearn.mypytable.MyPyTable at 0x7f86533d5d00>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "table = MyPyTable()\n",
    "table.load_from_file(\"Sydney_weather.csv\")"
   ]
  },
  {
   "source": [
    "### Discretizing Continuous Attributes\n",
    "\n",
    "The datatable has several attributes that are continuous variables that must first be discretized for use in the various classifiers, as well as the Random Forest Classifier."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cutoffs and labels for the continuous attributes\n",
    "temp_cutoffs = [0, 5, 10, 15, 20, 25, 30]\n",
    "temp_labels = [kk+1 for kk in range(len(temp_cutoffs))]\n",
    "humidity_cutoffs = [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "humidity_labels = [kk+1 for kk in range(len(humidity_cutoffs))]\n",
    "pressure_cutoffs = [950, 960, 970, 980, 990, 1000, 1010, 1020, 1030, 1040, 1050]\n",
    "pressure_labels = [kk+1 for kk in range(len(pressure_cutoffs))]\n",
    "# Get the attributes of interest from the datatable\n",
    "subdataset = table.get_multiple_columns([\"MinTemp\", \"MaxTemp\", \"WindGustDir\", \"Humidity9am\", \"Humidity3pm\", \"Pressure9am\", \"Pressure3pm\", \"RainToday\"])\n",
    "new_table = MyPyTable(data=subdataset, column_names=[\"MinTemp\", \"MaxTemp\", \"WindGustDir\", \"Humidity9am\", \"Humidity3pm\", \"Pressure9am\", \"Pressure3pm\", \"RainToday\"])\n",
    "# Remove all instances with NA\n",
    "new_table.remove_rows_with_missing_values()\n",
    "# Classify temps as continuous datat\n",
    "min_temp = new_table.get_column(\"MinTemp\")\n",
    "min_temp = myutils.classify_continuous_data(min_temp, temp_cutoffs, temp_labels, lower_inclusive_upper_exclusive=False)\n",
    "max_temp = new_table.get_column(\"MaxTemp\")\n",
    "max_temp = myutils.classify_continuous_data(max_temp, temp_cutoffs, temp_labels, lower_inclusive_upper_exclusive=False)\n",
    "humid9am = new_table.get_column(\"Humidity9am\")\n",
    "humid9am = myutils.classify_continuous_data(humid9am, humidity_cutoffs, humidity_labels, lower_inclusive_upper_exclusive=False)\n",
    "humid3pm = new_table.get_column(\"Humidity3pm\")\n",
    "humid3pm = myutils.classify_continuous_data(humid3pm, humidity_cutoffs, humidity_labels, lower_inclusive_upper_exclusive=False)\n",
    "pressure9am = new_table.get_column(\"Pressure9am\")\n",
    "pressure9am = myutils.classify_continuous_data(pressure9am, pressure_cutoffs, pressure_labels, lower_inclusive_upper_exclusive=False)\n",
    "pressure3pm = new_table.get_column(\"Pressure3pm\")\n",
    "pressure3pm = myutils.classify_continuous_data(pressure3pm, pressure_cutoffs, pressure_labels, lower_inclusive_upper_exclusive=False)\n",
    "windGust = new_table.get_column(\"WindGustDir\")\n",
    "rainToday = new_table.get_column(\"RainToday\")\n",
    "\n",
    "# Create the final table with the conditioning finished\n",
    "dataset = [ [str(min_temp[kk])] + [str(max_temp[kk])] + [str(humid9am[kk])] + [str(humid3pm[kk])] + [str(pressure9am[kk])] + [str(pressure3pm[kk])] + [str(windGust[kk])] + [str(rainToday[kk])] for kk in range(len(new_table.data))]\n",
    "table = MyPyTable(data=dataset, column_names=[\"MinTemp\", \"MaxTemp\", \"Humidity9am\", \"Humidity3pm\", \"Pressure9am\", \"Pressure3pm\",  \"WindGustDir\", \"RainToday\"])"
   ]
  },
  {
   "source": [
    "## Feature Selection using a Decision Tree Classifier\n",
    "\n",
    "A preliminary round of feature selection was performed on the basis of how many NA values the attribute column contained. We chose only to consider the attributes that had only a small percent of NA values to maintain a larger useable dataset. We chose not to replace the missing values as the classification problem is not favorable to such a large number of replacements. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n====================================================================\nDecision Rules:\n====================================================================\n\nIF Humidity9am = 10 AND WindGustDir = E THEN RainToday = Yes\nIF Humidity9am = 10 AND WindGustDir = ENE THEN RainToday = Yes\nIF Humidity9am = 10 AND WindGustDir = ESE THEN RainToday = Yes\nIF Humidity9am = 10 AND WindGustDir = N THEN RainToday = Yes\nIF Humidity9am = 10 AND WindGustDir = NE THEN RainToday = Yes\nIF Humidity9am = 10 AND WindGustDir = NNE THEN RainToday = Yes\nIF Humidity9am = 10 AND WindGustDir = NNW THEN RainToday = No\nIF Humidity9am = 10 AND WindGustDir = NW THEN RainToday = Yes\nIF Humidity9am = 10 AND WindGustDir = S THEN RainToday = Yes\nIF Humidity9am = 10 AND WindGustDir = SE THEN RainToday = Yes\nIF Humidity9am = 10 AND WindGustDir = SSE THEN RainToday = Yes\nIF Humidity9am = 10 AND WindGustDir = SSW THEN RainToday = Yes\nIF Humidity9am = 10 AND WindGustDir = SW THEN RainToday = Yes\nIF Humidity9am = 10 AND WindGustDir = W THEN RainToday = Yes\nIF Humidity9am = 10 AND WindGustDir = WNW THEN RainToday = No\nIF Humidity9am = 10 AND WindGustDir = WSW THEN RainToday = Yes\nIF Humidity9am = 2 THEN RainToday = No\nIF Humidity9am = 3 THEN RainToday = No\nIF Humidity9am = 4 AND MaxTemp = 3 THEN RainToday = No\nIF Humidity9am = 4 AND MaxTemp = 4 THEN RainToday = No\nIF Humidity9am = 4 AND MaxTemp = 5 THEN RainToday = No\nIF Humidity9am = 4 AND MaxTemp = 6 THEN RainToday = No\nIF Humidity9am = 5 AND WindGustDir = E THEN RainToday = No\nIF Humidity9am = 5 AND WindGustDir = ENE THEN RainToday = No\nIF Humidity9am = 5 AND WindGustDir = ESE THEN RainToday = No\nIF Humidity9am = 5 AND WindGustDir = N THEN RainToday = No\nIF Humidity9am = 5 AND WindGustDir = NE THEN RainToday = No\nIF Humidity9am = 5 AND WindGustDir = NNE THEN RainToday = No\nIF Humidity9am = 5 AND WindGustDir = NNW THEN RainToday = No\nIF Humidity9am = 5 AND WindGustDir = NW THEN RainToday = No\nIF Humidity9am = 5 AND WindGustDir = S THEN RainToday = No\nIF Humidity9am = 5 AND WindGustDir = SE THEN RainToday = No\nIF Humidity9am = 5 AND WindGustDir = SSE THEN RainToday = No\nIF Humidity9am = 5 AND WindGustDir = SSW THEN RainToday = No\nIF Humidity9am = 5 AND WindGustDir = SW THEN RainToday = No\nIF Humidity9am = 5 AND WindGustDir = W THEN RainToday = No\nIF Humidity9am = 5 AND WindGustDir = WNW THEN RainToday = No\nIF Humidity9am = 5 AND WindGustDir = WSW THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = E THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = ENE THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = ESE THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = N THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = NE THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = NNE THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = NNW THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = NW THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = S THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = SE THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = SSE THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = SSW THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = SW THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = W AND Pressure9am = 5 THEN RainToday = Yes\nIF Humidity9am = 6 AND WindGustDir = W AND Pressure9am = 6 THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = W AND Pressure9am = 7 THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = W AND Pressure9am = 8 THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = W AND Pressure9am = 9 THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = WNW THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = WSW AND Pressure9am = 5 THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = WSW AND Pressure9am = 6 THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = WSW AND Pressure9am = 7 AND MaxTemp = 3 THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = WSW AND Pressure9am = 7 AND MaxTemp = 4 THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = WSW AND Pressure9am = 7 AND MaxTemp = 5 THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = WSW AND Pressure9am = 7 AND MaxTemp = 6 THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = WSW AND Pressure9am = 8 THEN RainToday = No\nIF Humidity9am = 6 AND WindGustDir = WSW AND Pressure9am = 9 THEN RainToday = No\nIF Humidity9am = 7 AND WindGustDir = E THEN RainToday = No\nIF Humidity9am = 7 AND WindGustDir = ENE THEN RainToday = No\nIF Humidity9am = 7 AND WindGustDir = ESE THEN RainToday = No\nIF Humidity9am = 7 AND WindGustDir = N THEN RainToday = No\nIF Humidity9am = 7 AND WindGustDir = NE THEN RainToday = No\nIF Humidity9am = 7 AND WindGustDir = NNE THEN RainToday = No\nIF Humidity9am = 7 AND WindGustDir = NNW THEN RainToday = No\nIF Humidity9am = 7 AND WindGustDir = NW THEN RainToday = No\nIF Humidity9am = 7 AND WindGustDir = S THEN RainToday = No\nIF Humidity9am = 7 AND WindGustDir = SE THEN RainToday = No\nIF Humidity9am = 7 AND WindGustDir = SSE THEN RainToday = No\nIF Humidity9am = 7 AND WindGustDir = SSW THEN RainToday = No\nIF Humidity9am = 7 AND WindGustDir = SW THEN RainToday = No\nIF Humidity9am = 7 AND WindGustDir = W THEN RainToday = No\nIF Humidity9am = 7 AND WindGustDir = WNW THEN RainToday = No\nIF Humidity9am = 7 AND WindGustDir = WSW THEN RainToday = No\nIF Humidity9am = 8 AND WindGustDir = E THEN RainToday = No\nIF Humidity9am = 8 AND WindGustDir = ENE THEN RainToday = No\nIF Humidity9am = 8 AND WindGustDir = ESE THEN RainToday = No\nIF Humidity9am = 8 AND WindGustDir = N THEN RainToday = No\nIF Humidity9am = 8 AND WindGustDir = NE THEN RainToday = No\nIF Humidity9am = 8 AND WindGustDir = NNE THEN RainToday = No\nIF Humidity9am = 8 AND WindGustDir = NNW THEN RainToday = No\nIF Humidity9am = 8 AND WindGustDir = NW THEN RainToday = No\nIF Humidity9am = 8 AND WindGustDir = S THEN RainToday = No\nIF Humidity9am = 8 AND WindGustDir = SE THEN RainToday = No\nIF Humidity9am = 8 AND WindGustDir = SSE THEN RainToday = No\nIF Humidity9am = 8 AND WindGustDir = SSW THEN RainToday = No\nIF Humidity9am = 8 AND WindGustDir = SW THEN RainToday = No\nIF Humidity9am = 8 AND WindGustDir = W THEN RainToday = No\nIF Humidity9am = 8 AND WindGustDir = WNW THEN RainToday = No\nIF Humidity9am = 8 AND WindGustDir = WSW THEN RainToday = No\nIF Humidity9am = 9 AND WindGustDir = E THEN RainToday = Yes\nIF Humidity9am = 9 AND WindGustDir = ENE THEN RainToday = No\nIF Humidity9am = 9 AND WindGustDir = ESE THEN RainToday = Yes\nIF Humidity9am = 9 AND WindGustDir = N THEN RainToday = No\nIF Humidity9am = 9 AND WindGustDir = NE THEN RainToday = No\nIF Humidity9am = 9 AND WindGustDir = NNE THEN RainToday = No\nIF Humidity9am = 9 AND WindGustDir = NNW THEN RainToday = No\nIF Humidity9am = 9 AND WindGustDir = NW THEN RainToday = No\nIF Humidity9am = 9 AND WindGustDir = S THEN RainToday = Yes\nIF Humidity9am = 9 AND WindGustDir = SE AND MaxTemp = 3 THEN RainToday = Yes\nIF Humidity9am = 9 AND WindGustDir = SE AND MaxTemp = 4 THEN RainToday = Yes\nIF Humidity9am = 9 AND WindGustDir = SE AND MaxTemp = 5 THEN RainToday = Yes\nIF Humidity9am = 9 AND WindGustDir = SE AND MaxTemp = 6 THEN RainToday = No\nIF Humidity9am = 9 AND WindGustDir = SSE THEN RainToday = Yes\nIF Humidity9am = 9 AND WindGustDir = SSW THEN RainToday = Yes\nIF Humidity9am = 9 AND WindGustDir = SW THEN RainToday = Yes\nIF Humidity9am = 9 AND WindGustDir = W THEN RainToday = No\nIF Humidity9am = 9 AND WindGustDir = WNW THEN RainToday = Yes\nIF Humidity9am = 9 AND WindGustDir = WSW THEN RainToday = Yes\n\n====================================================================\n\n"
     ]
    }
   ],
   "source": [
    "# Create the X and y data\n",
    "X_data = table.get_multiple_columns([\"MinTemp\", \"MaxTemp\", \"WindGustDir\", \"Humidity9am\", \"Humidity3pm\", \"Pressure9am\", \"Pressure3pm\"])\n",
    "y_data = table.get_column(\"RainToday\")\n",
    "\n",
    "# Create the classifier and fit it\n",
    "decisionTreeClassifier = MyDecisionTreeClassifier()\n",
    "myevaluation.perform_holdout_method(decisionTreeClassifier, X_data, y_data, random_state=None, shuffle=False, normalize_X=False)\n",
    "\n",
    "# Make a visualization of the decision tree to determine the attributes of the most importance \n",
    "# in determining whether or not it will rain that day. This is to be used for feature selection\n",
    "# \n",
    "# decisionTreeClassifier.visualize_tree(\"SydneyAUS_DecisionTree_DOT\", \"SydneyAUS_DecisionTree\", attribute_names=[\"MinTemp\", \"MaxTemp\", \"WindGustDir\", \"Humidity9am\", \"Humidity3pm\", \"Pressure9am\", \"Pressure3pm\", \"RainToday\"])\n",
    "\n",
    "decisionTreeClassifier.print_decision_rules(attribute_names=[\"MinTemp\", \"MaxTemp\", \"WindGustDir\", \"Humidity9am\", \"Humidity3pm\", \"Pressure9am\", \"Pressure3pm\"], class_name=\"RainToday\")"
   ]
  },
  {
   "source": [
    "### Feature Selection\n",
    "\n",
    "Based on the decision tree classifier using entropy, it would seem that the most important attributes for classification are the following:\n",
    "\n",
    "* Humidity9am\n",
    "* WindGustDir\n",
    "* Pressure9am\n",
    "* MaxTemp\n",
    "\n",
    "Moving forward with classification, we feel that we will use our originally determined set of attributes for the classification given that they are all \"pairs\", i.e. Min/Max temperature and Pressure/Humidity at both 9am and 3pm. We believe this will be important for generating a reliable Random Forest classifier. However, for creating a Decision Tree Classifier and a Naive Bayes Classifier, the shortened attribute list posed above will be used."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Classification Using Multiple Classifier Types"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "To begin, we chose to use a decision tree classifier and stratified k-fold validation using k=10. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============================================================\nAccuracy Results\n============================================================\nStratified 10-Fold Cross Validation\nDecision Tree: accuracy = 0.7959618208516888, error rate = 0.20403817914831124\n"
     ]
    }
   ],
   "source": [
    "k_cross_validation = 10 # The number of folds for the (stratifed) cross-validation\n",
    "\n",
    "# Create the X and y data\n",
    "X_train = table.get_multiple_columns([\"MaxTemp\", \"WindGustDir\", \"Humidity9am\", \"Pressure9am\"])\n",
    "y_train = table.get_column(\"RainToday\")\n",
    "\n",
    "# Create the classifier and fit it using k-fold cross validation\n",
    "decisionTreeClassifier = MyDecisionTreeClassifier()\n",
    "correct_sum = 0\n",
    "# Get the train-test indices for cross-validation\n",
    "train_folds, test_folds = myevaluation.stratified_kfold_cross_validation(X_train, y_train, n_splits=k_cross_validation)\n",
    "# Run the fitting\n",
    "all_y_pred, all_y_actual = [], []\n",
    "for kk in range(k_cross_validation):\n",
    "    # Get the X,y train/test indices\n",
    "    train_indices, test_indices = train_folds[kk], test_folds[kk]\n",
    "    # Fit the classifier\n",
    "    X_test_indices, y_test_indices, y_test, y_test_pred = myevaluation.fit_classifier(decisionTreeClassifier, X_train, y_train, train_indices, test_indices, train_indices, test_indices, normalize_X=False)\n",
    "    # Fetch the y_test_actual values\n",
    "    y_test_actual = [y_train[kk] for kk in test_indices]\n",
    "    # Append these to their respective arrays\n",
    "    all_y_actual += y_test_actual\n",
    "    all_y_pred += y_test_pred\n",
    "    # Get the number correct\n",
    "    correct_sum += myutils.get_percent_correct(y_test_pred, y_test_actual)\n",
    "\n",
    "predictive_accuracy = correct_sum / k_cross_validation\n",
    "myutils.print_stratified_crossVal_results([predictive_accuracy], [\"Decision Tree\"], k_cross_validation, title=\"Accuracy Results\")"
   ]
  },
  {
   "source": [
    "### Notes on Decision Tree Classifier\n",
    "\n",
    "The decision tree classifier was able to do a good job of classifiying the dataset in the sense that its predictive accuracy is higher than the highest percentage of class labels in our binary classification problem."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "Next, we move to using a Naive Bayes Classifier, also using a stratified 10-fold cross-validation scheme."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============================================================\nAccuracy Results\n============================================================\nStratified 10-Fold Cross Validation\nNaive Bayes: accuracy = 0.7985895355127908, error rate = 0.20141046448720923\n"
     ]
    }
   ],
   "source": [
    "k_cross_validation = 10 # The number of folds for the (stratifed) cross-validation\n",
    "\n",
    "# Create the X and y data\n",
    "X_train = table.get_multiple_columns([\"MaxTemp\", \"WindGustDir\", \"Humidity9am\", \"Pressure9am\"])\n",
    "y_train = table.get_column(\"RainToday\")\n",
    "\n",
    "# create the classifier\n",
    "naiveBayesClassifier = MyNaiveBayesClassifier()\n",
    "correct_sum = 0\n",
    "all_y_pred, all_y_actual = [], []\n",
    "# Get the train-test indices for stratified cross-validation\n",
    "train_folds, test_folds = myevaluation.stratified_kfold_cross_validation(X_train, y_train, n_splits=k_cross_validation)\n",
    "\n",
    "# Fit the classifier\n",
    "for kk in range(k_cross_validation):\n",
    "    # Get the X,y train/test indices\n",
    "    train_indices, test_indices = train_folds[kk], test_folds[kk]\n",
    "    # Fit the  classifier\n",
    "    X_test_indices, y_test_indices, y_test, y_test_pred =  myevaluation.fit_classifier(naiveBayesClassifier, X_train, y_train, train_indices, test_indices, train_indices, test_indices, normalize_X=False)\n",
    "    # Fetch the y_test_actual values\n",
    "    y_test_actual = [y_train[kk] for kk in test_indices]\n",
    "    # Append these to their respective arrays\n",
    "    all_y_actual += y_test_actual\n",
    "    all_y_pred += y_test_pred\n",
    "    # Get the number correct\n",
    "    correct_sum += myutils.get_percent_correct(y_test_pred, y_test_actual)\n",
    "\n",
    "predictive_accuracy = correct_sum / k_cross_validation\n",
    "myutils.print_stratified_crossVal_results([predictive_accuracy], [\"Naive Bayes\"], k_cross_validation, title=\"Accuracy Results\")"
   ]
  },
  {
   "source": [
    "### Notes on Naive Bayes Classifier\n",
    "\n",
    "The Naive Bayes classifier was able to do a good job of classifiying the dataset--similar to that of the Decision Tree Classifier--in the sense that its predictive accuracy is higher than the highest percentage of class labels in our binary classification problem."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "Here, we are generating multiple random forest classifiers while modifying the variables N, M, and F described below. Multiple trials have been conducted and a summary of the results can be found below.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============================================================\nAccuracy Results\n============================================================\nStratified 10-Fold Cross Validation\nRandom Forest: accuracy = 0.7964023494860498, error rate = 0.20359765051395018\n"
     ]
    }
   ],
   "source": [
    "# Define the 3 random forest variables\n",
    "N = 30 # Total number of decision trees to generate\n",
    "M = 13 # Number of \"best\" trees ro keep\n",
    "F = 6 # Number of random attributes to select from\n",
    "\n",
    "k_cross_validation = 10 # The number of folds for the (stratifed) cross-validation\n",
    "\n",
    "# First, make sure everything is represented as a string\n",
    "X_train = table.get_multiple_columns([\"MinTemp\", \"MaxTemp\", \"WindGustDir\", \"Humidity9am\", \"Humidity3pm\", \"Pressure9am\", \"Pressure3pm\"])\n",
    "y_train = table.get_column(\"RainToday\")\n",
    "\n",
    "# Create the classifier and fit it using k-fold cross validation\n",
    "randForestClassifier = MyRandomForestClassifier(N, M, F)\n",
    "correct_sum = 0\n",
    "# Get the train-test indices for cross-validation\n",
    "train_folds, test_folds = myevaluation.stratified_kfold_cross_validation(X_train, y_train, n_splits=k_cross_validation)\n",
    "# Run the fitting\n",
    "all_y_pred, all_y_actual = [], []\n",
    "for kk in range(k_cross_validation):\n",
    "    # Get the X,y train/test indices\n",
    "    train_indices, test_indices = train_folds[kk], test_folds[kk]\n",
    "    # Fit the classifier\n",
    "    X_test_indices, y_test_indices, y_test, y_test_pred = myevaluation.fit_classifier(randForestClassifier, X_train, y_train, train_indices, test_indices, train_indices, test_indices, normalize_X=False)\n",
    "    # Fetch the y_test_actual values\n",
    "    y_test_actual = [y_train[kk] for kk in test_indices]\n",
    "    # Append these to their respective arrays\n",
    "    all_y_actual += y_test_actual\n",
    "    all_y_pred += y_test_pred\n",
    "    # Get the number correct\n",
    "    correct_sum += myutils.get_percent_correct(y_test_pred, y_test_actual)\n",
    "\n",
    "predictive_accuracy = correct_sum / k_cross_validation\n",
    "myutils.print_stratified_crossVal_results([predictive_accuracy], [\"Random Forest\"], k_cross_validation, title=\"Accuracy Results\")"
   ]
  },
  {
   "source": [
    "### Variable Modification Notes\n",
    "\n",
    "In this case, we are varying the variables N, M, and F in an attempt to generate the best random forest classifier. A summary of these results is given below:\n",
    "\n",
    "* N=20, M=7, F=2\n",
    "    * Accuracy = 0.752 -- My thought is that F=2 is a little too small. Increasing for next trial.\n",
    "* N=20, M=7, F=3\n",
    "    * Accuracy = 0.769 -- A slight to no improvement. Continuing with experimental changes.\n",
    "* N=20, M=9, F=5\n",
    "    * Accuracy = 0.792 -- Significant improvement from increasing F. Increasing N and M as well\n",
    "* N=30, M=11, F=5\n",
    "    * Accuracy = 0.774 -- No improvement. Next, planning on increasing both N and M and F \n",
    "* N=30, M=13, F=6\n",
    "    * Accuracy = 0.801 -- Better than the single decision tree classifier. Increasing  N and M a little more\n",
    "* N=40, M=17, F=6\n",
    "    * Accuracy = 0.801 -- No improvement and longer run time. Sticking with the previous trial. From curiosity, try lowering N and M\n",
    "* N=20, M=7, F=6\n",
    "    * Accuracy = 0.796\n",
    "\n",
    "It seems from the above trials that the best combination of variables for our dataset is N=30, M=13, and F=6. This has the best accuracy of all Classifiers that were tried and this is what will be used for our Flask App Deployment.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Saving the Best Classifier\n",
    "\n",
    "We want to upload our best classifier for use in a Heroku Web App. That is done here first. Note that the type of classifier will determine how the weather_app.py file needs to be structured.\n",
    "\n",
    "The app can be found on Heroku at: https://git.heroku.com/sydney-aus-weather-predictor.git"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the best classifier on all of the available data\n",
    "bestClassifier = MyRandomForestClassifier(30, 13, 6)\n",
    "\n",
    "X_train = table.get_multiple_columns([\"MinTemp\", \"MaxTemp\", \"WindGustDir\", \"Humidity9am\", \"Humidity3pm\", \"Pressure9am\", \"Pressure3pm\"])\n",
    "y_train = table.get_column(\"RainToday\")\n",
    "bestClassifier.fit(X_train, y_train)\n",
    "\n",
    "# Pickle the tree to use in the Heroku Web App\n",
    "packaged_object = [bestClassifier.header, bestClassifier.trees]\n",
    "# We want to pickle the packaged objects\n",
    "outfile = open(os.path.join(\"Heroku_Files\", \"bestClassifier.p\"), \"wb\")\n",
    "pickle.dump(packaged_object, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}